{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d01f4f-5112-4114-b780-7c6d427f974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul  9 13:27:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8              13W / 320W |   1639MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2200      G   /usr/lib/xorg/Xorg                          230MiB |\n",
      "|    0   N/A  N/A      2416      G   /usr/bin/gnome-shell                         38MiB |\n",
      "|    0   N/A  N/A      4105      G   ...seed-version=20240707-180341.351000      153MiB |\n",
      "|    0   N/A  N/A     19799      C   ...da3/envs/backdoor-attack/bin/python      238MiB |\n",
      "|    0   N/A  N/A     25707      C   ...da3/envs/backdoor-attack/bin/python      238MiB |\n",
      "|    0   N/A  N/A     26411      C   ...da3/envs/backdoor-attack/bin/python      238MiB |\n",
      "|    0   N/A  N/A     27191      C   ...da3/envs/backdoor-attack/bin/python      238MiB |\n",
      "|    0   N/A  N/A     27514      C   ...da3/envs/backdoor-attack/bin/python      238MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from numpy import load\n",
    "from tqdm import tqdm, trange\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "%run './Attention_based_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c8234da-269a-4a77-b29c-2d55eaa129c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA GeForce RTX 4080)\n"
     ]
    }
   ],
   "source": [
    "# check the availability of cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "with open('CIC2018-dataset-all-new.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8fb81e-c1c6-4db0-a835-92e143df3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1281/1281 [00:03<00:00, 384.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points shape: (10246, 2000)\n",
      "Labels shape: (10246,)\n",
      "Counter({0.0: 4715, 1.0: 4236, 2.0: 862, 4.0: 430, 3.0: 2, 5.0: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_points = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # progress bar\n",
    "    data_iter = tqdm.tqdm(\n",
    "        enumerate(train_loader),\n",
    "        total=len(train_loader),\n",
    "        bar_format=\"{l_bar}{r_bar}\"\n",
    "    )\n",
    "    for i, data in data_iter:  # Assuming you have an inference data loader\n",
    "        data = {key: value.to(device) for key, value in data.items()}\n",
    "        inputs, label = data[\"netformer_input\"], data[\"sequence_label\"]\n",
    "        \n",
    "        inputs = inputs.cpu().numpy()\n",
    "        label = label.cpu().numpy()\n",
    "        \n",
    "        # Collect the data points and labels\n",
    "        for j in range(inputs.shape[0]):\n",
    "            data_points.append(inputs[j])\n",
    "            labels.append(label[j])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data_points_np = np.array(data_points)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Print shapes to verify\n",
    "print('Data points shape:', data_points_np.shape)\n",
    "print('Labels shape:', labels_np.shape)\n",
    "\n",
    "print(Counter(labels_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042bb40a-73f7-4b5b-9b57-f56962ae631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data points shape: (40, 2000)\n",
      "Final Labels shape: (40,)\n",
      "Final Counter: Counter({0.0: 10, 1.0: 10, 2.0: 10, 3.0: 10})\n",
      "Confusion Matrix:\n",
      "[[1 0 0 0]\n",
      " [3 1 0 0]\n",
      " [0 1 1 0]\n",
      " [0 0 0 1]]\n",
      "Accuracy: 0.5000\n",
      "Precision: 0.6562\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.5083\n",
      "AUC: 0.7917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.25      1.00      0.40         1\n",
      "         1.0       0.50      0.25      0.33         4\n",
      "         2.0       1.00      0.50      0.67         2\n",
      "         3.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.50         8\n",
      "   macro avg       0.69      0.69      0.60         8\n",
      "weighted avg       0.66      0.50      0.51         8\n",
      "\n",
      "Final Data points shape: (80, 2000)\n",
      "Final Labels shape: (80,)\n",
      "Final Counter: Counter({0.0: 20, 1.0: 20, 2.0: 20, 3.0: 20})\n",
      "Confusion Matrix:\n",
      "[[4 1 0 0]\n",
      " [0 5 0 1]\n",
      " [0 0 2 0]\n",
      " [0 1 1 1]]\n",
      "Accuracy: 0.7500\n",
      "Precision: 0.7574\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.7412\n",
      "AUC: 0.8792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.80      0.89         5\n",
      "         1.0       0.71      0.83      0.77         6\n",
      "         2.0       0.67      1.00      0.80         2\n",
      "         3.0       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.72      0.74      0.71        16\n",
      "weighted avg       0.76      0.75      0.74        16\n",
      "\n",
      "Final Data points shape: (120, 2000)\n",
      "Final Labels shape: (120,)\n",
      "Final Counter: Counter({0.0: 30, 1.0: 30, 2.0: 30, 3.0: 30})\n",
      "Confusion Matrix:\n",
      "[[4 0 2 0]\n",
      " [0 6 1 0]\n",
      " [0 1 3 3]\n",
      " [0 1 0 3]]\n",
      "Accuracy: 0.6667\n",
      "Precision: 0.6979\n",
      "Recall: 0.6667\n",
      "F1 Score: 0.6679\n",
      "AUC: 0.9027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         6\n",
      "         1.0       0.75      0.86      0.80         7\n",
      "         2.0       0.50      0.43      0.46         7\n",
      "         3.0       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.67        24\n",
      "   macro avg       0.69      0.68      0.67        24\n",
      "weighted avg       0.70      0.67      0.67        24\n",
      "\n",
      "Final Data points shape: (200, 2000)\n",
      "Final Labels shape: (200,)\n",
      "Final Counter: Counter({0.0: 50, 1.0: 50, 2.0: 50, 3.0: 50})\n",
      "Confusion Matrix:\n",
      "[[ 5  1  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0  8  1]\n",
      " [ 0  0  3  7]]\n",
      "Accuracy: 0.8750\n",
      "Precision: 0.8839\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.8737\n",
      "AUC: 0.9645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.83      0.91         6\n",
      "         1.0       0.94      1.00      0.97        15\n",
      "         2.0       0.73      0.89      0.80         9\n",
      "         3.0       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.88      0.86      0.86        40\n",
      "weighted avg       0.88      0.88      0.87        40\n",
      "\n",
      "Final Data points shape: (320, 2000)\n",
      "Final Labels shape: (320,)\n",
      "Final Counter: Counter({0.0: 80, 1.0: 80, 2.0: 80, 3.0: 80})\n",
      "Confusion Matrix:\n",
      "[[13  6  1  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  0 19  1]\n",
      " [ 0  0  0 12]]\n",
      "Accuracy: 0.8750\n",
      "Precision: 0.9075\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.8731\n",
      "AUC: 0.9955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.65      0.79        20\n",
      "         1.0       0.67      1.00      0.80        12\n",
      "         2.0       0.95      0.95      0.95        20\n",
      "         3.0       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.88        64\n",
      "   macro avg       0.88      0.90      0.87        64\n",
      "weighted avg       0.91      0.88      0.87        64\n",
      "\n",
      "Final Data points shape: (500, 2000)\n",
      "Final Labels shape: (500,)\n",
      "Final Counter: Counter({0.0: 125, 1.0: 125, 2.0: 125, 3.0: 125})\n",
      "Confusion Matrix:\n",
      "[[26  3  1  1]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0 23  1]\n",
      " [ 0  0  0 30]]\n",
      "Accuracy: 0.9400\n",
      "Precision: 0.9463\n",
      "Recall: 0.9400\n",
      "F1 Score: 0.9395\n",
      "AUC: 0.9948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.84      0.91        31\n",
      "         1.0       0.83      1.00      0.91        15\n",
      "         2.0       0.96      0.96      0.96        24\n",
      "         3.0       0.94      1.00      0.97        30\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.93      0.95      0.94       100\n",
      "weighted avg       0.95      0.94      0.94       100\n",
      "\n",
      "Final Data points shape: (800, 2000)\n",
      "Final Labels shape: (800,)\n",
      "Final Counter: Counter({0.0: 200, 1.0: 200, 2.0: 200, 3.0: 200})\n",
      "Confusion Matrix:\n",
      "[[35  2  0  0]\n",
      " [ 0 43  0  0]\n",
      " [ 0  0 35  0]\n",
      " [ 0  0  0 45]]\n",
      "Accuracy: 0.9875\n",
      "Precision: 0.9881\n",
      "Recall: 0.9875\n",
      "F1 Score: 0.9875\n",
      "AUC: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.97        37\n",
      "         1.0       0.96      1.00      0.98        43\n",
      "         2.0       1.00      1.00      1.00        35\n",
      "         3.0       1.00      1.00      1.00        45\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n",
      "Final Data points shape: (1200, 2000)\n",
      "Final Labels shape: (1200,)\n",
      "Final Counter: Counter({0.0: 300, 1.0: 300, 2.0: 300, 3.0: 300})\n",
      "Confusion Matrix:\n",
      "[[56  2  3  1]\n",
      " [ 0 60  0  0]\n",
      " [ 0  0 60  0]\n",
      " [ 0  0  0 58]]\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9759\n",
      "Recall: 0.9750\n",
      "F1 Score: 0.9746\n",
      "AUC: 0.9998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95        62\n",
      "         1.0       0.97      1.00      0.98        60\n",
      "         2.0       0.95      1.00      0.98        60\n",
      "         3.0       0.98      1.00      0.99        58\n",
      "\n",
      "    accuracy                           0.97       240\n",
      "   macro avg       0.98      0.98      0.97       240\n",
      "weighted avg       0.98      0.97      0.97       240\n",
      "\n",
      "Final Data points shape: (1600, 2000)\n",
      "Final Labels shape: (1600,)\n",
      "Final Counter: Counter({0.0: 400, 1.0: 400, 2.0: 400, 3.0: 400})\n",
      "Confusion Matrix:\n",
      "[[79  4  5  1]\n",
      " [ 0 82  0  0]\n",
      " [ 0  0 79  0]\n",
      " [ 2  0  1 67]]\n",
      "Accuracy: 0.9594\n",
      "Precision: 0.9606\n",
      "Recall: 0.9594\n",
      "F1 Score: 0.9589\n",
      "AUC: 0.9954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.89      0.93        89\n",
      "         1.0       0.95      1.00      0.98        82\n",
      "         2.0       0.93      1.00      0.96        79\n",
      "         3.0       0.99      0.96      0.97        70\n",
      "\n",
      "    accuracy                           0.96       320\n",
      "   macro avg       0.96      0.96      0.96       320\n",
      "weighted avg       0.96      0.96      0.96       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select data points with class [0, 1, 2, 4]\n",
    "selected_classes = [0, 1, 2, 4]\n",
    "relabel_map = {0: 0, 1: 1, 2: 2, 4: 3}\n",
    "\n",
    "selected_indices = np.where(np.isin(labels_np, selected_classes))[0]\n",
    "\n",
    "selected_data = data_points_np[selected_indices]\n",
    "selected_labels = labels_np[selected_indices]\n",
    "\n",
    "# Relabel\n",
    "for old_label, new_label in relabel_map.items():\n",
    "    selected_labels[selected_labels == old_label] = new_label\n",
    "\n",
    "# Ensure 125 examples for each class\n",
    "\n",
    "sample_numeber_list = [10,20, 30, 50, 80, 125, 200, 300, 400]\n",
    "for sample in sample_numeber_list:\n",
    "    final_data = []\n",
    "    final_labels = []\n",
    "    for class_label in relabel_map.values():\n",
    "        class_indices = np.where(selected_labels == class_label)[0]\n",
    "        chosen_indices = np.random.choice(class_indices, sample, replace=False)\n",
    "        final_data.append(selected_data[chosen_indices])\n",
    "        final_labels.append(selected_labels[chosen_indices])\n",
    "    \n",
    "    final_data = np.concatenate(final_data)\n",
    "    final_labels = np.concatenate(final_labels)\n",
    "    \n",
    "    # Final data and labels shapes\n",
    "    print(\"Final Data points shape:\", final_data.shape)\n",
    "    print(\"Final Labels shape:\", final_labels.shape)\n",
    "    print(\"Final Counter:\", Counter(final_labels))\n",
    "\n",
    "    data_points = final_data \n",
    "    labels = final_labels\n",
    "    \n",
    "    # Data preprocessing\n",
    "    scaler = StandardScaler()\n",
    "    data_points = scaler.fit_transform(data_points)\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_points, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Training the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_prob = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Since roc_auc_score is not directly applicable to multi-class without specifying an average method, it's typically used for binary classification. For multi-class, we might use other metrics or one-vs-rest strategy.\n",
    "    # Here we will use the average='macro' method to calculate AUC for each class and average them\n",
    "    auc = roc_auc_score(y_test, y_prob, multi_class='ovo', average='macro')\n",
    "    \n",
    "    print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'AUC: {auc:.4f}')\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c96e20-6acb-4746-b81b-41bcb6e690a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[25  5  1  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0 24  0]\n",
      " [ 0  0  0 30]]\n",
      "Accuracy: 0.9400\n",
      "Precision: 0.9529\n",
      "Recall: 0.9400\n",
      "F1 Score: 0.9405\n",
      "AUC: 0.9995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.81      0.89        31\n",
      "         1.0       0.75      1.00      0.86        15\n",
      "         2.0       0.96      1.00      0.98        24\n",
      "         3.0       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.93      0.95      0.93       100\n",
      "weighted avg       0.95      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f956b7-5f03-44cf-a68a-41c8ad573f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
